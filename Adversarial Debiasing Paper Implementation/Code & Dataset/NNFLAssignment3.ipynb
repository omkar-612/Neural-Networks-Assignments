{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class AdversarialDebiasingMulti():\n",
        "\n",
        "    def __init__(self,\n",
        "                 protected_attribute_name,\n",
        "                 num_labels,\n",
        "                 scope_name,\n",
        "                 sess,\n",
        "                 seed=None,\n",
        "                 adversary_loss_weight=0.1,\n",
        "                 num_epochs=50,\n",
        "                 batch_size=128,\n",
        "                 classifier_num_hidden_units_1=100,\n",
        "                 classifier_num_hidden_units_2=100,\n",
        "                 adversary_num_hidden_units=100,\n",
        "                 debias=True,\n",
        "                 verbose=True,\n",
        "                 fairness_def='parity',\n",
        "                 saved_model=None):\n",
        "\n",
        "        self.scope_name = scope_name\n",
        "        self.seed = seed\n",
        "\n",
        "        self.protected_attribute_name = protected_attribute_name\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self.sess = sess\n",
        "        self.adversary_loss_weight = adversary_loss_weight\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.classifier_num_hidden_units_1 = classifier_num_hidden_units_1\n",
        "        self.classifier_num_hidden_units_2 = classifier_num_hidden_units_2\n",
        "        self.adversary_num_hidden_units = adversary_num_hidden_units\n",
        "        self.debias = debias\n",
        "        self.verbose = verbose\n",
        "        assert fairness_def in ['parity', 'equal_odds'], \\\n",
        "            \"fairness_def must be one of: 'parity', 'equal_odds'\"\n",
        "        self.fairness_def = fairness_def\n",
        "\n",
        "        self.features_dim = None\n",
        "        self.features_ph = None\n",
        "        self.protected_attributes_ph = None\n",
        "        self.true_labels_ph = None\n",
        "        self.pred_labels = None\n",
        "\n",
        "        self.label_translate = {}\n",
        "\n",
        "        self.saved_model = saved_model\n",
        "\n",
        "    def _classifier_model(self, features, features_dim, keep_prob):\n",
        "        \"\"\"Compute the classifier predictions for the outcome variable.\n",
        "        \"\"\"\n",
        "\n",
        "        with tf.compat.v1.variable_scope(\"classifier_model\"):\n",
        "            W1 = tf.compat.v1.get_variable('W1', [features_dim, self.classifier_num_hidden_units_1],\n",
        "                                  initializer=tf.keras.initializers.GlorotUniform(seed=self.seed1))\n",
        "            b1 = tf.Variable(tf.zeros(shape=[self.classifier_num_hidden_units_1]), name='b1')\n",
        "\n",
        "            h1 = tf.nn.relu(tf.matmul(features, W1) + b1)\n",
        "            h1 = tf.nn.dropout(h1, rate=1-keep_prob, seed=self.seed2)\n",
        "\n",
        "            # BEGIN NEW\n",
        "\n",
        "            W3 = tf.compat.v1.get_variable('W3', [self.classifier_num_hidden_units_1, self.classifier_num_hidden_units_2],\n",
        "                                  initializer=tf.keras.initializers.GlorotUniform(seed=self.seed5))\n",
        "            b3 = tf.Variable(tf.zeros(shape=[self.classifier_num_hidden_units_2]), name='b3')\n",
        "\n",
        "            h2 = tf.nn.relu(tf.matmul(h1, W3) + b3)\n",
        "            h2 = tf.nn.dropout(h2, rate=1-keep_prob, seed=self.seed6)\n",
        "\n",
        "            # END NEW\n",
        "\n",
        "            W2 = tf.compat.v1.get_variable('W2', [self.classifier_num_hidden_units_2, self.num_labels],\n",
        "                                 initializer=tf.keras.initializers.GlorotUniform(seed=self.seed3))\n",
        "            b2 = tf.Variable(tf.zeros(shape=[self.num_labels]), name='b2')\n",
        "\n",
        "            pred_logit = tf.matmul(h2, W2) + b2\n",
        "            pred_label = tf.nn.softmax(pred_logit)\n",
        "\n",
        "        return pred_label, pred_logit\n",
        "\n",
        "    def _adversary_model(self, pred_logits, true_labels, keep_prob):\n",
        "        \"\"\"Compute the adversary predictions for the protected attribute.\n",
        "        \"\"\"\n",
        "\n",
        "        with tf.compat.v1.variable_scope(\"adversary_model\"):\n",
        "            if self.fairness_def == 'parity':\n",
        "                W2 = tf.compat.v1.get_variable('W2', [self.num_labels, self.adversary_num_hidden_units],\n",
        "                                     initializer=tf.keras.initializers.GlorotUniform(seed=self.seed4))\n",
        "            elif self.fairness_def == 'equal_odds':\n",
        "                W2 = tf.compat.v1.get_variable('W2', [self.num_labels*2, self.adversary_num_hidden_units],\n",
        "                                     initializer=tf.keras.initializers.GlorotUniform(seed=self.seed4))\n",
        "\n",
        "            b2 = tf.Variable(tf.zeros(shape=[self.adversary_num_hidden_units]), name='b2')\n",
        "\n",
        "            if self.fairness_def == 'parity':\n",
        "                h1 = tf.nn.relu(tf.matmul(pred_logits, W2) + b2)\n",
        "            elif self.fairness_def == 'equal_odds':\n",
        "                h1 = tf.nn.relu(tf.matmul(tf.concat([pred_logits, true_labels], axis=1), W2) + b2)\n",
        "            h1 = tf.nn.dropout(h1, rate=1-keep_prob, seed=self.seed7)\n",
        "\n",
        "            W3 = tf.compat.v1.get_variable('W3', [self.adversary_num_hidden_units, 1],\n",
        "                                 initializer=tf.keras.initializers.GlorotUniform(seed=self.seed8))\n",
        "            b3 = tf.Variable(tf.zeros(shape=[1]), name='b3')\n",
        "\n",
        "\n",
        "            pred_protected_attribute_logit = tf.matmul(h1, W3) + b3\n",
        "            pred_protected_attribute_label = tf.sigmoid(pred_protected_attribute_logit)\n",
        "\n",
        "        return pred_protected_attribute_label, pred_protected_attribute_logit\n",
        "\n",
        "    def fit(self, features_set, metadata_set):\n",
        "        \"\"\"Compute the model parameters of the fair classifier using gradient\n",
        "        descent.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.seed is not None:\n",
        "            np.random.seed(self.seed)\n",
        "        ii32 = np.iinfo(np.int32)\n",
        "        self.seed1, self.seed2, self.seed3, self.seed4, self.seed5, self.seed6, self.seed7, self.seed8 = np.random.randint(ii32.min, ii32.max, size=8)\n",
        "\n",
        "        # Map the dataset labels to one-hot\n",
        "        def one_hot(x):\n",
        "            return np.eye(self.num_labels)[x]\n",
        "        temp_labels = metadata_set.copy()\n",
        "        label_names = sorted(temp_labels.label.unique())\n",
        "        for label_int in range(len(label_names)):\n",
        "            label_name = label_names[label_int]\n",
        "            self.label_translate[label_int] = label_name\n",
        "            temp_labels.loc[(temp_labels.label == label_name), 'label'] = label_int\n",
        "        temp_labels = np.array([one_hot(x) for x in temp_labels.label])\n",
        "\n",
        "        with tf.compat.v1.variable_scope(self.scope_name):\n",
        "            num_train_samples, self.features_dim = np.shape(features_set)\n",
        "\n",
        "            # Setup placeholders\n",
        "            self.features_ph = tf.compat.v1.placeholder(tf.float32, shape=[None, self.features_dim])\n",
        "            self.protected_attributes_ph = tf.compat.v1.placeholder(tf.float32, shape=[None,1])\n",
        "            self.true_labels_ph = tf.compat.v1.placeholder(tf.float32, shape=[None,self.num_labels])\n",
        "            self.keep_prob = tf.compat.v1.placeholder(tf.float32)\n",
        "\n",
        "            # Obtain classifier predictions and classifier loss\n",
        "            self.pred_labels, pred_logits = self._classifier_model(self.features_ph, self.features_dim, self.keep_prob)\n",
        "            pred_labels_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.true_labels_ph, logits=pred_logits))\n",
        "\n",
        "            if self.debias:\n",
        "                # Obtain adversary predictions and adversary loss\n",
        "                pred_protected_attributes_labels, pred_protected_attributes_logits = self._adversary_model(pred_logits, self.true_labels_ph, self.keep_prob)\n",
        "                pred_protected_attributes_loss = tf.reduce_mean(\n",
        "                    tf.nn.sigmoid_cross_entropy_with_logits(labels=self.protected_attributes_ph, logits=pred_protected_attributes_logits))\n",
        "\n",
        "            # Setup optimizers with learning rates\n",
        "            global_step = tf.Variable(0, trainable=False)\n",
        "            starter_learning_rate = 0.001\n",
        "            learning_rate = tf.compat.v1.train.exponential_decay(starter_learning_rate, global_step,\n",
        "                                                                 1000, 0.96, staircase=True)\n",
        "            classifier_opt = tf.compat.v1.train.AdamOptimizer(learning_rate)\n",
        "            if self.debias:\n",
        "                adversary_opt = tf.compat.v1.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "            classifier_vars = [var for var in tf.compat.v1.trainable_variables() if 'classifier_model' in var.name]\n",
        "            if self.debias:\n",
        "                adversary_vars = [var for var in tf.compat.v1.trainable_variables() if 'adversary_model' in var.name]\n",
        "                # Update classifier parameters\n",
        "                adversary_grads = {var: grad for (grad, var) in adversary_opt.compute_gradients(pred_protected_attributes_loss,\n",
        "                                                                                      var_list=classifier_vars)}\n",
        "            normalize = lambda x: x / (tf.norm(x) + np.finfo(np.float32).tiny)\n",
        "\n",
        "            classifier_grads = []\n",
        "            for (grad,var) in classifier_opt.compute_gradients(pred_labels_loss, var_list=classifier_vars):\n",
        "                if self.debias:\n",
        "                    unit_adversary_grad = normalize(adversary_grads[var])\n",
        "                    grad -= tf.reduce_sum(grad * unit_adversary_grad) * unit_adversary_grad\n",
        "                    grad -= self.adversary_loss_weight * adversary_grads[var]\n",
        "                classifier_grads.append((grad, var))\n",
        "            classifier_minimizer = classifier_opt.apply_gradients(classifier_grads, global_step=global_step)\n",
        "\n",
        "            if self.debias:\n",
        "                # Update adversary parameters\n",
        "                with tf.control_dependencies([classifier_minimizer]):\n",
        "                    adversary_minimizer = adversary_opt.minimize(pred_protected_attributes_loss, var_list=adversary_vars)#, global_step=global_step)\n",
        "\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            self.sess.run(tf.compat.v1.local_variables_initializer())\n",
        "\n",
        "        if self.saved_model:\n",
        "            if self.verbose:\n",
        "                print('RETRIEVING SAVED MODEL: {}'.format(self.saved_model), file=sys.stderr)\n",
        "            try:\n",
        "                saver = tf.compat.v1.train.import_meta_graph(self.saved_model + '/model.meta')\n",
        "                saver.restore(self.sess, tf.compat.v1.train.latest_checkpoint('./' + self.saved_model + '/'))\n",
        "                return self\n",
        "            except:\n",
        "                import traceback\n",
        "                print(sys.exc_info()[0], file=sys.stderr, flush=True)\n",
        "                print(sys.exc_info()[1], file=sys.stderr, flush=True)\n",
        "                print(traceback.print_tb(sys.exc_info()[2]), file=sys.stderr, flush=True)\n",
        "                print('Failed: continuing', file=sys.stderr)\n",
        "\n",
        "            # Begin training\n",
        "        with tf.compat.v1.variable_scope(self.scope_name):\n",
        "            for epoch in range(self.num_epochs):\n",
        "                shuffled_ids = np.random.choice(num_train_samples, num_train_samples, replace=False)\n",
        "                for i in range(num_train_samples//self.batch_size):\n",
        "                    batch_ids = shuffled_ids[self.batch_size*i: self.batch_size*(i+1)]\n",
        "                    batch_features = features_set.loc[batch_ids]\n",
        "                    batch_labels = temp_labels[batch_ids]\n",
        "                    batch_protected_attributes = np.reshape(list(metadata_set[self.protected_attribute_name].loc[batch_ids]), [-1,1])\n",
        "\n",
        "                    batch_feed_dict = {self.features_ph: batch_features,\n",
        "                                       self.true_labels_ph: batch_labels,\n",
        "                                       self.protected_attributes_ph: batch_protected_attributes,\n",
        "                                       self.keep_prob: 0.8}\n",
        "\n",
        "                    if self.debias:\n",
        "                        _, _, pred_labels_loss_value, pred_protected_attributes_loss_vale = self.sess.run([classifier_minimizer,\n",
        "                                       adversary_minimizer,\n",
        "                                       pred_labels_loss,\n",
        "                                       pred_protected_attributes_loss], feed_dict=batch_feed_dict)\n",
        "                        if i % 200 == 0 and self.verbose:\n",
        "                            print(\"epoch %d; iter: %d; batch classifier loss: %f; batch adversarial loss: %f\" % (epoch, i, pred_labels_loss_value,\n",
        "                                                                                     pred_protected_attributes_loss_vale),\n",
        "                                  file=sys.stderr, flush=True)\n",
        "                    else:\n",
        "                        _, pred_labels_loss_value = self.sess.run(\n",
        "                            [classifier_minimizer,\n",
        "                             pred_labels_loss], feed_dict=batch_feed_dict)\n",
        "                        if i % 200 == 0 and self.verbose:\n",
        "                            print(\"epoch %d; iter: %d; batch classifier loss: %f\" % (\n",
        "                                  epoch, i, pred_labels_loss_value),\n",
        "                                  file=sys.stderr, flush=True)\n",
        "\n",
        "        if self.saved_model:\n",
        "            model_name = self.saved_model + '/model'\n",
        "            if self.verbose:\n",
        "                print('SAVING MODEL: {}'.format(model_name), file=sys.stderr)\n",
        "            saver = tf.compat.v1.train.Saver()\n",
        "            saver.save(self.sess, model_name)\n",
        "            # print(self.__dict__, file=sys.stderr)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, features_set, metadata_set):\n",
        "        \"\"\"Obtain the predictions for the provided dataset using the fair\n",
        "        classifier learned.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.seed is not None:\n",
        "            np.random.seed(self.seed)\n",
        "\n",
        "        def one_hot(x):\n",
        "            return np.eye(self.num_labels)[x]\n",
        "        temp_labels = metadata_set.copy()\n",
        "        for label_int in self.label_translate:\n",
        "            label_name = self.label_translate[label_int]\n",
        "            temp_labels.loc[(temp_labels.label == label_name), 'label'] = label_int\n",
        "        try:\n",
        "            temp_labels = np.array([one_hot(x) for x in temp_labels.label])\n",
        "        except IndexError:\n",
        "            temp_labels = np.array([np.zeros(len(self.label_translate)) for x in temp_labels.label])\n",
        "\n",
        "        num_test_samples, _ = np.shape(features_set)\n",
        "\n",
        "        samples_covered = 0\n",
        "        pred_labels = []\n",
        "        while samples_covered < num_test_samples:\n",
        "            start = samples_covered\n",
        "            end = samples_covered + self.batch_size\n",
        "            if end > num_test_samples:\n",
        "                end = num_test_samples\n",
        "            batch_ids = np.arange(start, end)\n",
        "            batch_features = features_set.loc[batch_ids]\n",
        "            batch_labels = temp_labels[batch_ids]\n",
        "            batch_protected_attributes = np.reshape(list(metadata_set[self.protected_attribute_name].loc[batch_ids]), [-1,1])\n",
        "\n",
        "            batch_feed_dict = {self.features_ph: batch_features,\n",
        "                               self.true_labels_ph: batch_labels,\n",
        "                               self.protected_attributes_ph: batch_protected_attributes,\n",
        "                               self.keep_prob: 1.0}\n",
        "\n",
        "            pred_labels += self.sess.run(self.pred_labels, feed_dict=batch_feed_dict).tolist()\n",
        "            samples_covered += len(batch_features)\n",
        "\n",
        "        pred_labels = np.array(pred_labels, dtype=np.float64)\n",
        "        dataset_new = metadata_set.copy()\n",
        "        for label_num in self.label_translate:\n",
        "            dataset_new['pred_score_{}'.format(self.label_translate[label_num])] = pred_labels[:,label_num]\n",
        "        dataset_new['pred_label'] = [self.label_translate[x] for x in (np.argmax(pred_labels, axis=1)).astype(np.int32).tolist()]\n",
        "\n",
        "        return dataset_new"
      ],
      "metadata": {
        "id": "AjpOCxssnnsn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jIJJuc0xfk4-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "trcH4l_dnk8i"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "#sys.path.append(\"../\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4ez_-5CXnk8n"
      },
      "outputs": [],
      "source": [
        "compas = pd.read_csv('compas.csv', index_col=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cYbewbm5nk8o",
        "outputId": "7f21df74-a602-47b1-d43f-32910ae7931d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-bb82d85ca353>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  meta['label'] = meta.label.astype(int)\n"
          ]
        }
      ],
      "source": [
        "def prepare_meta_and_features(df, protected_attribute_name):\n",
        "    meta = df[[protected_attribute_name, 'label']]\n",
        "    features = df.drop(columns=[protected_attribute_name, 'label'])\n",
        "    \n",
        "    for col in features.columns:\n",
        "        data = features[col]\n",
        "        if pd.api.types.is_numeric_dtype(data):\n",
        "            data -= np.min(data,axis=0)\n",
        "            data /= (np.max(data,axis=0) - np.min(data,axis=0))\n",
        "            features[col] = data\n",
        "        else:\n",
        "            dummies = pd.get_dummies(data, prefix=col)\n",
        "            features[col] = dummies\n",
        "            \n",
        "    meta['label'] = meta.label.astype(int)\n",
        "    return meta, features\n",
        "\n",
        "meta, features = prepare_meta_and_features(compas, 'race')\n",
        "\n",
        "features_train, features_test, meta_train, meta_test = train_test_split(features, meta, test_size=0.2, random_state=42, stratify=meta.label)\n",
        "\n",
        "meta_train.reset_index(drop=True, inplace=True)\n",
        "meta_test.reset_index(drop=True, inplace=True)\n",
        "features_train.reset_index(drop=True, inplace=True)\n",
        "features_test.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eQCGdWlKnk8q"
      },
      "outputs": [],
      "source": [
        "def get_predictions(debias=True, fairness_def='parity', adv_loss_weight=2, prot_attr='race'):\n",
        "    sess = tf.compat.v1.Session()\n",
        "    model = AdversarialDebiasingMulti(\n",
        "        protected_attribute_name=prot_attr,\n",
        "        num_labels=len(meta_train.label.unique()),\n",
        "        scope_name='biased_classifier',\n",
        "        debias=debias,\n",
        "        adversary_loss_weight=adv_loss_weight,\n",
        "        fairness_def=fairness_def,\n",
        "        verbose=False,\n",
        "        num_epochs=64,\n",
        "        classifier_num_hidden_units_1=60,\n",
        "        classifier_num_hidden_units_2=20,\n",
        "        sess=sess\n",
        "    )\n",
        "    model.fit(features_train, meta_train)\n",
        "    predictions = model.predict(features_test, meta_test)\n",
        "    sess.close()\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDxYkQbWnk8q"
      },
      "source": [
        "***\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Binary Protected Attribute (Race)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IKXGKy9Lnk8s"
      },
      "outputs": [],
      "source": [
        "def print_stats(df):\n",
        "    print('PERFORMANCE:\\n')\n",
        "    print(classification_report(df.label, df.pred_label))\n",
        "    print('\\nBIAS:')\n",
        "    rw = len(df.loc[(df.race==1) & (df.pred_label==1)]) / len(df.loc[df.race==1])\n",
        "    print('\\nproportion of White people predicted to reoffend: ' + str(rw))\n",
        "    rn = len(df.loc[(df.race==0) & (df.pred_label==1)]) / len(df.loc[df.race==0])\n",
        "    print('proportion of Nonwhite people predicted to reoffend: ' + str(rn))\n",
        "    print('\\tRATE GAP = ' + str(rw - rn))\n",
        "    tprw = len(df.loc[(df.race==1) & (df.pred_label==1) & (df.label==1)]) / len(df.loc[(df.race==1) & (df.label==1)])\n",
        "    print('\\nTPR for White people: ' + str(tprw))\n",
        "    tprn = len(df.loc[(df.race==0) & (df.pred_label==1) & (df.label==1)]) / len(df.loc[(df.race==0) & (df.label==1)])\n",
        "    print('TPR for Nonwhite people: ' + str(tprn))\n",
        "    print('\\tTPR GAP = ' + str(tprw - tprn))\n",
        "    fprw = len(df.loc[(df.race==1) & (df.pred_label==1) & (df.label==0)]) / len(df.loc[(df.race==1) & (df.label==0)])\n",
        "    print('\\nFPR for White people: ' + str(fprw))\n",
        "    fprn = len(df.loc[(df.race==0) & (df.pred_label==1) & (df.label==0)]) / len(df.loc[(df.race==0) & (df.label==0)])\n",
        "    print('FPR for Nonwhite people: ' + str(fprn))\n",
        "    print('\\tFPR GAP = ' + str(fprw - fprn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCF4CGFfnk8t"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0ToDBKKlnk8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956c36fc-7e75-4a58-c6e9-d06670656344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PERFORMANCE:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.75      0.70       672\n",
            "           1       0.63      0.51      0.56       562\n",
            "\n",
            "    accuracy                           0.64      1234\n",
            "   macro avg       0.64      0.63      0.63      1234\n",
            "weighted avg       0.64      0.64      0.64      1234\n",
            "\n",
            "\n",
            "BIAS:\n",
            "\n",
            "proportion of White people predicted to reoffend: 0.26277372262773724\n",
            "proportion of Nonwhite people predicted to reoffend: 0.4155528554070474\n",
            "\tRATE GAP = -0.15277913277931016\n",
            "\n",
            "TPR for White people: 0.34782608695652173\n",
            "TPR for Nonwhite people: 0.571072319201995\n",
            "\tTPR GAP = -0.22324623224547324\n",
            "\n",
            "FPR for White people: 0.208\n",
            "FPR for Nonwhite people: 0.2677725118483412\n",
            "\tFPR GAP = -0.05977251184834123\n"
          ]
        }
      ],
      "source": [
        "predictions = get_predictions(debias=False)\n",
        "print_stats(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FElIrKRYnk8v"
      },
      "source": [
        "## Parity Fairness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ooFsjX49nk8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d64c35-c63f-44a8-8583-20b9ff3b7c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PERFORMANCE:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.77      0.71       672\n",
            "           1       0.66      0.54      0.60       562\n",
            "\n",
            "    accuracy                           0.67      1234\n",
            "   macro avg       0.66      0.66      0.66      1234\n",
            "weighted avg       0.66      0.67      0.66      1234\n",
            "\n",
            "\n",
            "BIAS:\n",
            "\n",
            "proportion of White people predicted to reoffend: 0.2846715328467153\n",
            "proportion of Nonwhite people predicted to reoffend: 0.4155528554070474\n",
            "\tRATE GAP = -0.13088132256033208\n",
            "\n",
            "TPR for White people: 0.40993788819875776\n",
            "TPR for Nonwhite people: 0.5935162094763092\n",
            "\tTPR GAP = -0.18357832127755147\n",
            "\n",
            "FPR for White people: 0.204\n",
            "FPR for Nonwhite people: 0.24644549763033174\n",
            "\tFPR GAP = -0.04244549763033176\n"
          ]
        }
      ],
      "source": [
        "predictions = get_predictions(fairness_def='parity', adv_loss_weight=15)\n",
        "print_stats(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqKw_7ACnk8w"
      },
      "source": [
        "## Equal Odds Fairness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "doh_SpUVnk8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf07060-165a-4793-84e3-b5019a430ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PERFORMANCE:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.69      0.67       672\n",
            "           1       0.61      0.56      0.58       562\n",
            "\n",
            "    accuracy                           0.63      1234\n",
            "   macro avg       0.63      0.63      0.63      1234\n",
            "weighted avg       0.63      0.63      0.63      1234\n",
            "\n",
            "\n",
            "BIAS:\n",
            "\n",
            "proportion of White people predicted to reoffend: 0.35036496350364965\n",
            "proportion of Nonwhite people predicted to reoffend: 0.46051032806804376\n",
            "\tRATE GAP = -0.11014536456439411\n",
            "\n",
            "TPR for White people: 0.4906832298136646\n",
            "TPR for Nonwhite people: 0.5935162094763092\n",
            "\tTPR GAP = -0.10283297966264465\n",
            "\n",
            "FPR for White people: 0.26\n",
            "FPR for Nonwhite people: 0.3341232227488152\n",
            "\tFPR GAP = -0.07412322274881517\n"
          ]
        }
      ],
      "source": [
        "predictions = get_predictions(fairness_def='equal_odds', adv_loss_weight=50)\n",
        "print_stats(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuPWdWnwnk8x"
      },
      "source": [
        "***\n",
        "# Continuous Protected Attribute (Age)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xws-yHjwnk8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc50e23-efe3-48ba-cb6d-3ef0d7d58e09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-bb82d85ca353>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  meta['label'] = meta.label.astype(int)\n"
          ]
        }
      ],
      "source": [
        "meta, features = prepare_meta_and_features(compas, 'age')\n",
        "\n",
        "features_train, features_test, meta_train, meta_test = train_test_split(features, meta, test_size=0.2, random_state=42, stratify=meta.label)\n",
        "\n",
        "meta_train.reset_index(drop=True, inplace=True)\n",
        "meta_test.reset_index(drop=True, inplace=True)\n",
        "features_train.reset_index(drop=True, inplace=True)\n",
        "features_test.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "s5SAIkwcnk8y"
      },
      "outputs": [],
      "source": [
        "def print_stats(df):\n",
        "    print('PERFORMANCE:\\n')\n",
        "    print(classification_report(df.label, df.pred_label))\n",
        "    print('\\nBIAS:')\n",
        "    corr = pearsonr(df.age, df.pred_label)[0]\n",
        "    corr_1 = pearsonr(df.loc[df.label==1].age, df.loc[df.label==1].pred_label)[0]\n",
        "    corr_0 = pearsonr(df.loc[df.label==0].age, df.loc[df.label==0].pred_label)[0]\n",
        "    print('\\nCorrelation between age and predicted label: ' + str(corr))\n",
        "    print('\\nCorrelation between age and predicted label, conditional on true label=1: ' + str(corr_1))\n",
        "    print('\\nCorrelation between age and predicted label, conditional on true label=0: ' + str(corr_0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtIz7C_Qnk8y"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_6rQNDTXnk8y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f72ed0-7f73-4ccf-ca85-20142b137612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PERFORMANCE:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.71      0.69       672\n",
            "           1       0.63      0.59      0.61       562\n",
            "\n",
            "    accuracy                           0.66      1234\n",
            "   macro avg       0.65      0.65      0.65      1234\n",
            "weighted avg       0.65      0.66      0.65      1234\n",
            "\n",
            "\n",
            "BIAS:\n",
            "\n",
            "Correlation between age and predicted label: -0.21704837297500712\n",
            "\n",
            "Correlation between age and predicted label, conditional on true label=1: -0.13651086589086187\n",
            "\n",
            "Correlation between age and predicted label, conditional on true label=0: -0.20308977275693996\n"
          ]
        }
      ],
      "source": [
        "predictions = get_predictions(debias=False, prot_attr='age')\n",
        "print_stats(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRA-3DKqnk8y"
      },
      "source": [
        "## Parity Fairness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ECggF8-Hnk8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77552f56-a70e-41de-97bc-499985dfa9bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PERFORMANCE:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.57      0.63       672\n",
            "           1       0.58      0.71      0.64       562\n",
            "\n",
            "    accuracy                           0.63      1234\n",
            "   macro avg       0.64      0.64      0.63      1234\n",
            "weighted avg       0.64      0.63      0.63      1234\n",
            "\n",
            "\n",
            "BIAS:\n",
            "\n",
            "Correlation between age and predicted label: -0.2845084632439279\n",
            "\n",
            "Correlation between age and predicted label, conditional on true label=1: -0.21988036081725576\n",
            "\n",
            "Correlation between age and predicted label, conditional on true label=0: -0.26635022690514965\n"
          ]
        }
      ],
      "source": [
        "predictions = get_predictions(prot_attr='age', fairness_def='parity', adv_loss_weight=0.001)\n",
        "print_stats(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu1_PwtQnk8z"
      },
      "source": [
        "## Equal Odds Fairness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "s9cAShRsnk8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7daa9b-ecd9-4b41-e8e2-9272ca8bad5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PERFORMANCE:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.02      0.04       672\n",
            "           1       0.46      0.99      0.63       562\n",
            "\n",
            "    accuracy                           0.46      1234\n",
            "   macro avg       0.60      0.51      0.34      1234\n",
            "weighted avg       0.62      0.46      0.31      1234\n",
            "\n",
            "\n",
            "BIAS:\n",
            "\n",
            "Correlation between age and predicted label: -0.14938091723340735\n",
            "\n",
            "Correlation between age and predicted label, conditional on true label=1: -0.12330738980768029\n",
            "\n",
            "Correlation between age and predicted label, conditional on true label=0: -0.1538273315296457\n"
          ]
        }
      ],
      "source": [
        "predictions = get_predictions(prot_attr='age', fairness_def='equal_odds', adv_loss_weight=0.001)\n",
        "print_stats(predictions)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}